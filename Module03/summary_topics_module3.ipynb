{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebcb7aa3",
   "metadata": {},
   "source": [
    "Top 5 essential code snippets from Module 3 (Classification) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c8f333",
   "metadata": {},
   "source": [
    "1. Split the data\n",
    "    Split the full dataset into train, validation, and test.\n",
    "    This lets you train, tune, and finally test your model fairly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df_fulltrain,df_test= train_test_split(df,test_size=0.2,random_state=1)\n",
    "# df_train,df_val = train_test_split(df_fulltrain,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292fb5a1",
   "metadata": {},
   "source": [
    "2. One-Hot Encode Categorical Features\n",
    "    Convert each row of your DataFrame into a dictionary (feature â†’ value).\n",
    "    DictVectorizer automatically one-hot encodes categorical features into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction import DictVectorizer\n",
    "# dict_train= df_train[categorical+numerical].to_dict(orient='records') \n",
    "# dv=DictVectorizer(sparse=False)\n",
    "# X_train=dv.fit_transform(dict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb516b9",
   "metadata": {},
   "source": [
    "3. Train Logistic Regression Model\n",
    "    Train a logistic regression model using the training data.\n",
    "    The model learns how features relate to churn (1 = churn, 0 = stay)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# model= LogisticRegression(solver='lbfgs',max_iter=1000)\n",
    "# model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b23ea",
   "metadata": {},
   "source": [
    "4. Make Predictions\n",
    "    Predict probabilities (how likely each customer is to churn).\n",
    "    Apply a threshold (0.5) to turn probabilities into 0/1 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_val= df_val[categorical+numerical].to_dict(orient='records')\n",
    "# X_val= dv.transform(dict_val)\n",
    "\n",
    "# y_pred= model.predict_proba(X_val)[:,1] # churn probability\n",
    "# churn_decision= (y_pred>=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346f37e",
   "metadata": {},
   "source": [
    "5. Evaluate Accuracy\n",
    "    Compare predictions with actual outcomes.\n",
    "    Accuracy = % of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy= (y_val==churn_decision).mean()\n",
    "# print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13573bb5",
   "metadata": {},
   "source": [
    "6. Interpret the Model\n",
    "    This shows the bias (intercept) and feature weights (coefficients).\n",
    "    Positive weights = higher churn probability, negative = lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f582caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.intercept_[0])\n",
    "# print(model.coef_[0],round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
